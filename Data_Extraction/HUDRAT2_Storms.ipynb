{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7854ad-3ed1-4aa7-8184-c1a0ea2408e6",
   "metadata": {},
   "source": [
    "# Hurricanes \n",
    "- Hurricanes are not bearish by default\n",
    "- Refiners often benefit\n",
    "- Integrated majors barely flinch\n",
    "- Only extreme or prolonged disruptions move stocks\n",
    "- The signal exists ‚Äî but only in carefully defined events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ea9b66-71bf-4540-af9d-68b66f247ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for file at: D:\\MS_Data_Science_Thesis\\Data_Extraction\\Downloaded_datasets\\hurdat2_atlantic.txt\n",
      "‚úÖ File found. Ready to parse.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# On your Local PC\n",
    "BASE_DIR = Path(r\"D:\\MS_Data_Science_Thesis\\Data_Extraction\")\n",
    "OUTPUT_DIR = BASE_DIR / \"Raw_Data_Folder\"\n",
    "\n",
    "# Look for the file in the Output Directory\n",
    "HURDAT_FILE = BASE_DIR / \"Downloaded_datasets\" / \"hurdat2_atlantic.txt\"\n",
    "\n",
    "print(f\"Checking for file at: {HURDAT_FILE}\")\n",
    "\n",
    "if not HURDAT_FILE.exists():\n",
    "    print(\"‚ö†Ô∏è File not found! Please ensure 'hurdat2_atlantic.txt' is uploaded to the 'Raw_Data_Folder' in your GitHub repo or Google Drive.\")\n",
    "else:\n",
    "    print(\"‚úÖ File found. Ready to parse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d01d02f-bd8c-4ed9-b198-5386fae78b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hurdat2(path: Path):\n",
    "    rows = []\n",
    "    storm_id = storm_name = None\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            parts = [p.strip() for p in line.split(\",\")]\n",
    "            \n",
    "            # Header lines have 3 or 4 parts (ID, Name, Count, [Empty])\n",
    "            if len(parts) in [3, 4] and parts[0].startswith(('AL', 'CP', 'EP')):\n",
    "                storm_id = parts[0]\n",
    "                storm_name = parts[1]\n",
    "                continue\n",
    "\n",
    "            # Data lines have at least 8 key parts\n",
    "            if len(parts) >= 8 and storm_id:\n",
    "                try:\n",
    "                    # Date (0) and Time (1)\n",
    "                    dt = pd.to_datetime(parts[0] + parts[1], format='%Y%m%d%H%M')\n",
    "\n",
    "                    # Lat (4) and Lon (5)\n",
    "                    lat_s, lon_s = parts[4], parts[5]\n",
    "                    lat = float(lat_s[:-1]) * (-1 if 'S' in lat_s.upper() else 1)\n",
    "                    lon = float(lon_s[:-1]) * (-1 if 'W' in lon_s.upper() else 1)\n",
    "\n",
    "                    rows.append({\n",
    "                        \"storm_id\": storm_id,\n",
    "                        \"storm_name\": storm_name,\n",
    "                        \"datetime\": dt,\n",
    "                        \"status\": parts[3],\n",
    "                        \"lat\": lat,\n",
    "                        \"lon\": lon,\n",
    "                        \"wind_kt\": int(parts[6]) if parts[6].lstrip('-').isdigit() else None,\n",
    "                        \"pressure_mb\": int(parts[7]) if parts[7].lstrip('-').isdigit() else None\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Run the parser\n",
    "hurdat_df = parse_hurdat2(HURDAT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b26650b9-9f36-473a-9dc5-ad9017c10128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parsed 55230 rows from 1991 unique storms.\n",
      "üìÇ Saved to: D:\\MS_Data_Science_Thesis\\Data_Extraction\\Raw_Data_Folder\\hurdat2_atlantic_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_id</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>wind_kt</th>\n",
       "      <th>pressure_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1851-06-25 21:00:00</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   storm_id storm_name            datetime status   lat   lon  wind_kt  \\\n",
       "0  AL011851    UNNAMED 1851-06-25 00:00:00     HU  28.0 -94.8       80   \n",
       "1  AL011851    UNNAMED 1851-06-25 06:00:00     HU  28.0 -95.4       80   \n",
       "2  AL011851    UNNAMED 1851-06-25 12:00:00     HU  28.0 -96.0       80   \n",
       "3  AL011851    UNNAMED 1851-06-25 18:00:00     HU  28.1 -96.5       80   \n",
       "4  AL011851    UNNAMED 1851-06-25 21:00:00     HU  28.2 -96.8       80   \n",
       "\n",
       "   pressure_mb  \n",
       "0         -999  \n",
       "1         -999  \n",
       "2         -999  \n",
       "3         -999  \n",
       "4         -999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Parse the text file\n",
    "hurdat_df = parse_hurdat2(HURDAT_FILE)\n",
    "\n",
    "if not hurdat_df.empty:\n",
    "    # 2. Sort and Clean\n",
    "    hurdat_df = hurdat_df.sort_values([\"storm_id\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "    # 3. Save to the new directory\n",
    "    out_csv = OUTPUT_DIR / \"hurdat2_atlantic_clean.csv\"\n",
    "    hurdat_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Parsed {len(hurdat_df)} rows from {hurdat_df['storm_id'].nunique()} unique storms.\")\n",
    "    print(f\"üìÇ Saved to: {out_csv}\")\n",
    "    \n",
    "    # Preview\n",
    "    display(hurdat_df.head())\n",
    "else:\n",
    "    print(\"‚ùå No data was parsed. Check if the input .txt file is in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb7cb7-875e-476c-812d-6dd451e0cf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba71e55-f554-4aee-b4a9-e18d13bd34fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa83ca-3a95-4354-85b7-f38e9ee26749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sidd_ds)",
   "language": "python",
   "name": "sidd_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
