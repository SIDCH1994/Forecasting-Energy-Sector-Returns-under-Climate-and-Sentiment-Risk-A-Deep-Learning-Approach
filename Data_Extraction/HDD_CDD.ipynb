{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db201be-ae7e-4087-ab92-fe436b8f7354",
   "metadata": {},
   "source": [
    "# HDD-CDD\n",
    "- HDD/CDD do not directly drive energy stock prices\n",
    "- They do influence demand, which can move prices\n",
    "- Stocks respond only when weather alters expectations or cash flows\n",
    "- The signal is real but subtle\n",
    "- Poor modeling makes it look useless; good modeling makes it valuable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427220-7a5b-4b02-8d94-9ff8bf39afe6",
   "metadata": {},
   "source": [
    "HDD-CDD of several cities is collected using the Meteostat library\n",
    "#### Source: Meteostat – public data aggregation service.\n",
    "- Meteostat collects and harmonizes\n",
    "- NOAA’s Global Historical Climatology Network (GHCN),\n",
    "- Environment and Climate Change Canada,\n",
    "- Deutscher Wetterdienst (DWD, Germany), and\n",
    "- MET Norway, among others\n",
    "\n",
    "Accessed via the official meteostat Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc19474-cdfc-4ed5-8f3e-e64e24f72699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if missing\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def ensure(p):\n",
    "    try: importlib.import_module(p)\n",
    "    except: subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
    "\n",
    "ensure(\"meteostat\"); ensure(\"pandas\"); ensure(\"tqdm\")\n",
    "\n",
    "# Imports\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from meteostat import Daily, Stations   # <-- Stations is imported here\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483cd8aa-ba2e-4158-bfce-486e47649a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save\n",
    "ROOT = Path.cwd()\n",
    "RAW_DAILY   = ROOT / \"data_raw\" / \"hddcdd\" / \"daily\"\n",
    "CLEAN_MONTH = ROOT / \"data_clean\"\n",
    "RAW_DAILY.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_MONTH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Locations (lat, lon)\n",
    "LOCATIONS = {\n",
    "    \"CorpusChristi_TX\": (27.8006, -97.3964),\n",
    "    \"Houston_TX\":       (29.7604, -95.3698),\n",
    "    \"NewYork_NY\":       (40.7128, -74.0060),\n",
    "}\n",
    "\n",
    "# Date range (start recent to avoid legacy gaps)\n",
    "START = datetime(2021, 1, 1)\n",
    "END   = datetime.today()\n",
    "\n",
    "# Degree-day base (°F)\n",
    "BASE_F = 65.0\n",
    "\n",
    "# Optional: hard-coded airport fallback if auto-pick fails\n",
    "FALLBACK_STATIONS = {\n",
    "    \"CorpusChristi_TX\": \"KCRP\",  # Corpus Christi Intl\n",
    "    \"Houston_TX\":       \"KIAH\",  # George Bush Intercontinental\n",
    "    \"NewYork_NY\":       \"KJFK\",  # JFK\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042dc885-99fd-46f4-a3f4-790fa7f86aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_f(c):\n",
    "    return c * 9/5 + 32\n",
    "\n",
    "def add_hdd_cdd(df, base_f=65.0):\n",
    "    # Prefer tavg; if missing, use (tmin+tmax)/2 when available\n",
    "    tmean_c = df[\"tavg\"].copy() if \"tavg\" in df.columns else pd.Series(pd.NA, index=df.index)\n",
    "    if \"tmin\" in df.columns and \"tmax\" in df.columns:\n",
    "        mask = tmean_c.isna()\n",
    "        tmean_c.loc[mask] = (df.loc[mask, \"tmin\"] + df.loc[mask, \"tmax\"]) / 2\n",
    "\n",
    "    tmean_f = c_to_f(tmean_c.astype(float))\n",
    "    hdd = (base_f - tmean_f).clip(lower=0)\n",
    "    cdd = (tmean_f - base_f).clip(lower=0)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"tmean_f\"] = tmean_f.round(2)\n",
    "    out[\"HDD\"] = hdd.round(2)\n",
    "    out[\"CDD\"] = cdd.round(2)\n",
    "    return out\n",
    "\n",
    "def best_station_df(lat, lon, start, end, max_candidates=8):\n",
    "    \"\"\"\n",
    "    Return a 1-row Stations DataFrame (not an ID string).\n",
    "    We pass this DataFrame directly to meteostat.Daily(...).\n",
    "    \"\"\"\n",
    "    st = Stations().nearby(lat, lon)\n",
    "    cand = st.fetch(max_candidates)\n",
    "\n",
    "    if cand is None or len(cand) == 0:\n",
    "        return None\n",
    "\n",
    "    best_row = None\n",
    "    best_non_na = -1\n",
    "\n",
    "    # iterate over candidate rows by position; keep each row as a 1-row DataFrame\n",
    "    for i in range(len(cand)):\n",
    "        row1 = cand.iloc[[i]]            # keep DataFrame shape (1 row)\n",
    "        df = Daily(row1, start, end).fetch()\n",
    "        if df.empty:\n",
    "            continue\n",
    "        # count days with at least one temperature value\n",
    "        have = df[[\"tavg\",\"tmin\",\"tmax\"]].notna().any(axis=1).sum()\n",
    "        if have > best_non_na:\n",
    "            best_non_na = have\n",
    "            best_row = row1\n",
    "\n",
    "    return best_row  # 1-row DataFrame or None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea37b03-1643-41aa-980c-905bb83edefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]Warning: Cannot load daily/2021/4MIKP.csv.gz from https://data.meteostat.net/\n",
      " 33%|███▎      | 1/3 [01:06<02:12, 66.33s/it]Warning: Cannot load daily/2021/877AW.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2021/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2021/KIWS0.csv.gz from https://data.meteostat.net/\n",
      "100%|██████████| 3/3 [03:10<00:00, 63.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen stations: {'CorpusChristi_TX': {'name': 'Ingleside / Millsville', 'icao': 'KTFP', 'wmo': None}, 'Houston_TX': {'name': 'Houston Intercontinental', 'icao': 'KIAH', 'wmo': '72243'}, 'NewYork_NY': {'name': 'Newark Airport', 'icao': 'KEWR', 'wmo': '72502'}}\n",
      "Daily files saved to: C:\\Users\\siddh\\OneDrive - Texas A&M University-Corpus Christi\\Documents\\SIDDHARTHA\\MASTER'S TAMUCC\\MASTER'S THESIS\\Dr.Pal Thesis\\Data\\Scenario-2\\HDD_CDD\\data_raw\\hddcdd\\daily\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>tmean_f</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tavg</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CorpusChristi_TX</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>49.82</td>\n",
       "      <td>15.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CorpusChristi_TX</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>51.26</td>\n",
       "      <td>13.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CorpusChristi_TX</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>56.12</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CorpusChristi_TX</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>63.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CorpusChristi_TX</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>66.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.56</td>\n",
       "      <td>14.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location       date  tmean_f    HDD   CDD  tmin  tmax  tavg  prcp  \\\n",
       "0  CorpusChristi_TX 2021-01-01    49.82  15.18  0.00   4.6  14.9   9.9  <NA>   \n",
       "1  CorpusChristi_TX 2021-01-02    51.26  13.74  0.00   4.6  17.4  10.7   0.0   \n",
       "2  CorpusChristi_TX 2021-01-03    56.12   8.88  0.00   6.1  20.8  13.4   0.0   \n",
       "3  CorpusChristi_TX 2021-01-04    63.50   1.50  0.00  11.2  24.6  17.5   0.0   \n",
       "4  CorpusChristi_TX 2021-01-05    66.56   0.00  1.56  14.2  23.7  19.2   3.8   \n",
       "\n",
       "   snow  \n",
       "0  <NA>  \n",
       "1  <NA>  \n",
       "2  <NA>  \n",
       "3  <NA>  \n",
       "4  <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_daily = []\n",
    "chosen = {}\n",
    "\n",
    "for name, (lat, lon) in tqdm(LOCATIONS.items()):\n",
    "    st_row = best_station_df(lat, lon, START, END)\n",
    "\n",
    "    # Fallback: try a known airport code if search fails\n",
    "    if st_row is None and name in FALLBACK_STATIONS:\n",
    "        try:\n",
    "            st_row = Stations().id(FALLBACK_STATIONS[name]).fetch(1)  # 1-row DF\n",
    "            if st_row is None or len(st_row) == 0:\n",
    "                st_row = None\n",
    "        except Exception:\n",
    "            st_row = None\n",
    "\n",
    "    if st_row is None:\n",
    "        print(f\"[{name}] No station found for {START.date()}–{END.date()}\")\n",
    "        continue\n",
    "\n",
    "    # Keep something human-readable about the station we picked (name/icao if present)\n",
    "    meta_cols = [c for c in [\"name\",\"icao\",\"wmo\",\"id\"] if c in st_row.columns]\n",
    "    chosen[name] = st_row[meta_cols].to_dict(orient=\"records\")[0] if meta_cols else {\"picked\":\"ok\"}\n",
    "\n",
    "    # Fetch daily & compute HDD/CDD\n",
    "    df = Daily(st_row, START, END).fetch().reset_index().rename(columns={\"time\":\"date\"})\n",
    "    if df.empty:\n",
    "        print(f\"[{name}] Station returned no data\")\n",
    "        continue\n",
    "\n",
    "    df = add_hdd_cdd(df, base_f=BASE_F)\n",
    "\n",
    "    keep = [\"date\",\"tmean_f\",\"HDD\",\"CDD\",\"tmin\",\"tmax\",\"tavg\",\"prcp\",\"snow\"]\n",
    "    for k in keep:\n",
    "        if k not in df.columns: df[k] = pd.NA\n",
    "    df = df[keep]\n",
    "    df.insert(0, \"location\", name)\n",
    "\n",
    "    outpath = RAW_DAILY / f\"{name}_daily_hddcdd.csv\"\n",
    "    df.to_csv(outpath, index=False)\n",
    "    all_daily.append(df)\n",
    "\n",
    "print(\"Chosen stations:\", chosen)\n",
    "print(f\"Daily files saved to: {RAW_DAILY}\")\n",
    "if all_daily:\n",
    "    display(all_daily[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a8d7af-9bf9-476d-88c7-dacb62c011c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-city files:\n",
      " - C:\\Users\\siddh\\OneDrive - Texas A&M University-Corpus Christi\\Documents\\SIDDHARTHA\\MASTER'S TAMUCC\\MASTER'S THESIS\\Dr.Pal Thesis\\Data\\Scenario-2\\HDD_CDD\\data_clean\\hddcdd_daily_by_city\\CorpusChristi_TX_daily_hddcdd.csv\n",
      " - C:\\Users\\siddh\\OneDrive - Texas A&M University-Corpus Christi\\Documents\\SIDDHARTHA\\MASTER'S TAMUCC\\MASTER'S THESIS\\Dr.Pal Thesis\\Data\\Scenario-2\\HDD_CDD\\data_clean\\hddcdd_daily_by_city\\Houston_TX_daily_hddcdd.csv\n",
      " - C:\\Users\\siddh\\OneDrive - Texas A&M University-Corpus Christi\\Documents\\SIDDHARTHA\\MASTER'S TAMUCC\\MASTER'S THESIS\\Dr.Pal Thesis\\Data\\Scenario-2\\HDD_CDD\\data_clean\\hddcdd_daily_by_city\\NewYork_NY_daily_hddcdd.csv\n"
     ]
    }
   ],
   "source": [
    "# Export one CSV per city with full daily info\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Paths (adjust ROOT if your notebook isn't in the same folder you used before)\n",
    "ROOT = Path.cwd()\n",
    "RAW_DAILY = ROOT / \"data_raw\" / \"hddcdd\" / \"daily\"\n",
    "OUT_DIR   = ROOT / \"data_clean\" / \"hddcdd_daily_by_city\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Get the combined daily dataframe\n",
    "try:\n",
    "    _ = all_daily  # check if exists\n",
    "    daily_all = pd.concat(all_daily, ignore_index=True)\n",
    "except NameError:\n",
    "    files = glob.glob(str(RAW_DAILY / \"*_daily_hddcdd.csv\"))\n",
    "    if not files:\n",
    "        raise SystemExit(\"No daily files found. Run the download cell first.\")\n",
    "    frames = [pd.read_csv(f, parse_dates=[\"date\"]) for f in files]\n",
    "    daily_all = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# 2) Keep columns in the order you showed\n",
    "cols = [\"location\",\"date\",\"tmean_f\",\"HDD\",\"CDD\",\"tmin\",\"tmax\",\"tavg\",\"prcp\",\"snow\"]\n",
    "for c in cols:\n",
    "    if c not in daily_all.columns:\n",
    "        daily_all[c] = pd.NA\n",
    "daily_all = daily_all[cols]\n",
    "daily_all[\"date\"] = pd.to_datetime(daily_all[\"date\"])\n",
    "\n",
    "# 3) Write one CSV per city\n",
    "saved = []\n",
    "for loc, g in daily_all.groupby(\"location\", sort=True):\n",
    "    out_path = OUT_DIR / f\"{loc}_daily_hddcdd.csv\"\n",
    "    g.sort_values(\"date\").to_csv(out_path, index=False)\n",
    "    saved.append(out_path)\n",
    "\n",
    "print(\"Saved per-city files:\")\n",
    "for p in saved:\n",
    "    print(\" -\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d762079-e1dd-4467-a17f-9a6910e51ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
