{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d61869f-972d-4bf3-a113-af83e271a962",
   "metadata": {},
   "source": [
    "# XLE - Energy Select Sector SPDR Fund.\n",
    "It’s an ETF that tracks large U.S. energy companies in the S&P 500 (e.g., integrated majors, refiners, E&Ps).\n",
    "- Think of it as a benchmark for the U.S. energy sector.\n",
    "\n",
    "#### How XLE impacts energy company stock prices\n",
    "**Direct impact:** If a company is inside XLE, its stock moves with ETF flows.\n",
    "\n",
    "\n",
    "#### When XLE rises:\n",
    "- Energy sector sentiment is strong\n",
    "- Capital flows into energy\n",
    "- Component stocks often rise\n",
    "\n",
    "#### When XLE falls:\n",
    "- Sector outflows\n",
    "- Component stocks usually decline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592aa412-3464-43da-8983-8351eac0f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[xle] Fetching 'XLE' from Yahoo Finance from 2010-01-01 onward...\n",
      "[xle] Saved raw XLE prices to D:\\MS_Data_Science_Thesis\\Data_Extraction\\Downloaded_datasets\\xle_yahoo_raw.csv\n",
      "[xle] Saved clean XLE index to D:\\MS_Data_Science_Thesis\\Data_Extraction\\Raw_Data_Folder\\XLE_daily.csv\n",
      "[xle] rows=4052  range=2010-01-04 → 2026-02-11\n"
     ]
    }
   ],
   "source": [
    "# ===================== CONFIG: XLE (Energy Sector Index) =====================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "START_DATE = \"2010-01-01\"\n",
    "XLE_TICKER = \"XLE\"\n",
    "\n",
    "BASE_DIR   = Path(r\"D:\\MS_Data_Science_Thesis\\Data_Extraction\")\n",
    "RAW_DIR    = BASE_DIR / \"Downloaded_datasets\"\n",
    "CLEAN_DIR  = BASE_DIR / \"Raw_Data_Folder\"\n",
    "\n",
    "RAW_XLE_CSV   = RAW_DIR   / \"xle_yahoo_raw.csv\"\n",
    "CLEAN_XLE_CSV = CLEAN_DIR / \"XLE_daily.csv\"\n",
    "# ===========================================================================\n",
    "\n",
    "\n",
    "# ---------- ensure folders exist (safe if already created) ----------\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def fetch_xle_from_yahoo(ticker: str, start_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch daily prices for XLE from Yahoo Finance using yfinance.\n",
    "    Returns a DataFrame with DatetimeIndex and OHLCV columns.\n",
    "    \"\"\"\n",
    "    print(f\"[xle] Fetching {ticker!r} from Yahoo Finance from {start_date} onward...\")\n",
    "    # Explicitly set auto_adjust=False so we keep 'Adj Close'\n",
    "    df = yf.download(ticker, start=start_date, auto_adjust=False, progress=False)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _flatten_columns(cols):\n",
    "    \"\"\"\n",
    "    Turn possible MultiIndex columns into simple string names.\n",
    "    Example: ('Adj Close', 'XLE') -> 'Adj Close_XLE'\n",
    "    \"\"\"\n",
    "    flat = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, tuple):\n",
    "            parts = [str(x) for x in c if x is not None and str(x) != \"\"]\n",
    "            flat.append(\"_\".join(parts))\n",
    "        else:\n",
    "            flat.append(str(c))\n",
    "    return flat\n",
    "\n",
    "\n",
    "def clean_xle_df(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw XLE OHLCV data:\n",
    "      - flatten MultiIndex columns if needed\n",
    "      - keep Adjusted Close as the sector index\n",
    "      - reset index, rename columns\n",
    "      - drop missing values\n",
    "    Output: date, xle_adj_close\n",
    "    \"\"\"\n",
    "    if df_raw.empty:\n",
    "        print(\"[xle] WARNING: raw XLE dataframe is empty.\")\n",
    "        return df_raw.copy()\n",
    "\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Flatten column names if they are tuples / MultiIndex\n",
    "    df.columns = _flatten_columns(df.columns)\n",
    "\n",
    "    # Reset index so date is a column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Flatten again (index column may also become tuple in some cases)\n",
    "    df.columns = _flatten_columns(df.columns)\n",
    "\n",
    "    # First column should be the date\n",
    "    date_col = df.columns[0]\n",
    "\n",
    "    # Try to find an \"Adj Close\" column (possibly like 'Adj Close', 'Adj Close_XLE', etc.)\n",
    "    adj_cols = [c for c in df.columns if \"adj\" in c.lower() and \"close\" in c.lower()]\n",
    "\n",
    "    # Fallback to \"Close\" if adj not found\n",
    "    if not adj_cols:\n",
    "        adj_cols = [c for c in df.columns if c.lower() == \"close\"]\n",
    "\n",
    "    if not adj_cols:\n",
    "        raise ValueError(f\"[xle] Could not find an 'Adj Close' or 'Close' column in: {df.columns.tolist()}\")\n",
    "\n",
    "    value_col = adj_cols[0]\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            date_col: \"date\",\n",
    "            value_col: \"xle_adj_close\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Enforce dtypes\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    df[\"xle_adj_close\"] = pd.to_numeric(df[\"xle_adj_close\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"xle_adj_close\"])\n",
    "\n",
    "    # Final tidy ordering\n",
    "    df = df.sort_values(\"date\")[[\"date\", \"xle_adj_close\"]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- run pipeline ----------\n",
    "try:\n",
    "    # 1. Fetch from Yahoo (raw)\n",
    "    xle_raw = fetch_xle_from_yahoo(XLE_TICKER, START_DATE)\n",
    "\n",
    "    # 2. Save raw as reference\n",
    "    xle_raw.to_csv(RAW_XLE_CSV)\n",
    "    print(f\"[xle] Saved raw XLE prices to {RAW_XLE_CSV}\")\n",
    "\n",
    "    # 3. Clean and standardize\n",
    "    xle_clean = clean_xle_df(xle_raw)\n",
    "\n",
    "    # 4. Save clean daily CSV (long format: date + single value column)\n",
    "    xle_clean.to_csv(CLEAN_XLE_CSV, index=False)\n",
    "    print(f\"[xle] Saved clean XLE index to {CLEAN_XLE_CSV}\")\n",
    "\n",
    "    # 5. Quick QA printout\n",
    "    if not xle_clean.empty:\n",
    "        dmin = xle_clean[\"date\"].min().date()\n",
    "        dmax = xle_clean[\"date\"].max().date()\n",
    "        print(f\"[xle] rows={len(xle_clean)}  range={dmin} → {dmax}\")\n",
    "    else:\n",
    "        print(\"[xle] WARNING: clean XLE dataset is empty after filtering/cleaning.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[xle] ERROR while fetching or processing XLE data:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0662c3-a8e5-48ac-928c-ffdc29391d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sidd_ds)",
   "language": "python",
   "name": "sidd_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
